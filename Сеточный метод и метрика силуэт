{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1b798040",
      "metadata": {
        "id": "1b798040"
      },
      "source": [
        "Во всех задания требуется написать эффективные реализации, используя функционал numpy. Использовать numba, вызывать код из C или использовать посторонние библиотеки запрещается. В заданиях указаны ориентировочные времена работы. Они могут отличаться на разных машинах, поэтому на вашем компьютере правильное решение может работать как быстрее, так и медленнее. Если в задании указано, что время работы 8 мин, а у вас работает 10, скорее всего, это не страшно. Если же указано 8 мин, а код работает 8 часов, это вряд ли можно списать на медленный компьютер."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c05df98c",
      "metadata": {
        "id": "c05df98c"
      },
      "source": [
        "# 1. Перебор параметров по сетке"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ee7facc",
      "metadata": {
        "id": "3ee7facc"
      },
      "source": [
        "Пусть задана функция вида $$ f(x) = \\dfrac{d \\log^a{(x)}}{1 + x^b e^{\\frac{-c}{x}}} $$\n",
        "Требуется восстановиться параметры $a, b, c$ и $d$ по значениям функции в узлах заданной сетки. Для этого:\n",
        "1. Выберете некоторые значения $a, b, c$ и $d$. Например, $a=1.2$, $b=0.4$, $c=1.5$, $d=1.0$;\n",
        "2. Сгенерируйте сетку, на которой будут вычисляться значение функции. Сетка должна содержать $1,000$ узлов. Например, хорошо подойдет равномерная сетка на отрезке $[1, 100]$ с $1,000$ узлов;\n",
        "3. Вычислите значения $f(x)$ в узлах сгенерированной сетки;\n",
        "4. Далее требуется восстановить величины $a, b, c$ и $d$ по значениям $f(x)$ в узлах сгенерированной сетки. Для этого сгенерируйте возможные наборы значений для параметров $a, b, c$ и $d$. Для каждого из параметров должно быть 100 (или 101, если удобнее) значений. Например, для приведенных выше значений хорошо подойдут равномерные сетки на отрезках $[1, 2]$, $[0, 1]$, $[1, 2]$ и $[0, 2]$ соответственно с 101 узлом каждая. Всего имеем $101^4$ комбинаций параметров. Требуется, перебирая всевозможные наборы параметров и вычисления значения функции в узлах сетки, найти те значения, которые будут обеспечивать минимум $l_2$ нормы разности правильного и построенного набора значений.\n",
        "\n",
        "Ориентировочное время работы при правильной организации перебора $-$ 8 мин.\n",
        "\n",
        "P.S. В задании требуется просто разумно реализовать перебор на numpy. Придумывать правильный алгоритм перебора, отсечения или как-либо еще \"по-умному\" производить оптимизацию не требуется."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import linalg as LA\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "dcIxWLpoP06P"
      },
      "id": "dcIxWLpoP06P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_size = 1000 # размер сетки\n",
        "set_size = 101   # размер выборки для значений коэффициентов\n",
        "a, b, c, d = 1.2, 0.4, 1.5, 1.0\n",
        "\n",
        "def f(a, b, c, d, x):\n",
        "  return d * np.log(x) ** a / (1 + x ** b * np.exp(-c / x))\n",
        "\n",
        "# генерация сетки\n",
        "net = np.linspace(1, 100, net_size)\n",
        "\n",
        "# вычисление значений функции на сгенерированной сетке\n",
        "values = np.array(f(a, b, c, d, net))\n",
        "\n",
        "# генерация возможных значений a, b, c d\n",
        "a_set = np.array(np.linspace(1, 2, set_size))\n",
        "b_set = np.array(np.linspace(0, 1, set_size))\n",
        "c_set = np.array(np.linspace(1, 2, set_size))\n",
        "d_set = np.array(np.linspace(0, 2, set_size))\n",
        "\n",
        "# стартовое значение для минимальной нормы и коэффициентов\n",
        "min_norm = LA.norm(f(np.mean(a_set), np.mean(b_set), np.mean(c_set), \n",
        "                     np.mean(d_set), net))\n",
        "\n",
        "coeff = [np.mean(a_set), np.mean(b_set), np.mean(c_set), np.mean(d_set)]\n",
        "\n",
        "for i in tqdm(range(set_size)):\n",
        "  for j in range(set_size):\n",
        "    # tensor[a][b][c][d][значение на элементе сетки(axis=3)]    \n",
        "    tensor = f(a_set[:, None, None], b_set[None, :, None], c_set[i], d_set[j],\n",
        "               net[None, None, :])\n",
        "\n",
        "    # tensor_mod[a][b][c][d] - значение нормы невязки на этом наборе параметров\n",
        "    tensor_mod = LA.norm(tensor - values[None, None, :], 2, axis=2)\n",
        "    \n",
        "    min_tmp = np.min(tensor_mod)\n",
        "    if min_tmp < min_norm:\n",
        "      min_norm = min_tmp\n",
        "      pos = np.where(tensor_mod == min_tmp)\n",
        "      coeff = *pos[0], *pos[1], i, j\n",
        "\n",
        "print(\"\\na =\", a_set[coeff[0]], \"\\nb =\", b_set[coeff[1]], \"\\nc =\", \n",
        "      c_set[coeff[2]], \"\\nd =\", d_set[coeff[3]],\"\\nmin_norm =\", min_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrNHSoD4h98F",
        "outputId": "a0c66374-2b39-48bd-8d92-3e42648afce9"
      },
      "id": "NrNHSoD4h98F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 101/101 [12:18<00:00,  7.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "a = 1.2 \n",
            "b = 0.4 \n",
            "c = 1.5 \n",
            "d = 1.0 \n",
            "min_norm = 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3bcd5b6",
      "metadata": {
        "id": "a3bcd5b6"
      },
      "source": [
        "# 2. Преобразования тензоров"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed490c63",
      "metadata": {
        "id": "ed490c63"
      },
      "source": [
        "1. Сгенерируйте случайный тензор (случайный numpy.array) размера $\\underbrace{2 \\times 2 \\times \\dots \\times 2}_\\text{16 раз}$.\n",
        "2. Последовательно произведите с ним следующую процедуру. Разбейте множители на пары: $$ (2 \\times 2) \\times (2 \\times 2) $$ и вычислите кронекерово произведение векторов в скобках. Повторяйте процедуру пока не останется один вектор. $$ 2 \\times 2 \\times 2 \\times 2 \\to (2 \\times 2) \\times (2 \\times 2) \\to 4 \\times 4 \\to (4 \\times 4) \\to 16 $$ В результате должен получиться вектор длины $2^{16}$.\n",
        "3. Из построенного вектора попробуйте восстановить исходное представление. А именно, пусть имеется вектор длины $16$. С помощью reshape его можно преобразовать к матрице $4 \\times 4$. Для матрицы $4 \\times 4$ постройте оптимальное одноранговое приближение - это будет произведение двух векторов размера 4. Для каждого из векторов длины 4 повторите операцию.\n",
        "$$ 16 \\to 4 \\times 4 \\to (2 \\times 2) \\times (2 \\times 2) \\to 2 \\times 2 \\times 2 \\times 2 $$\n",
        "\n",
        "Схема метода:\n",
        "<img src=\"Tensor2-1.png\" width=\"500\"/>\n",
        "<img src=\"Tensor3-1.png\" width=\"500\"/>\n",
        "\n",
        "(На самом деле это схема для чуть более сложного варианта, значок суммы можно игнорировать)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9cbb803",
      "metadata": {
        "id": "d9cbb803"
      },
      "source": [
        "# 3. Метрика кластеризации"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "399dc7c5",
      "metadata": {
        "id": "399dc7c5"
      },
      "source": [
        "(Задание честно своровано из задач весеннего семестра по курсу машинного обучения)\n",
        "\n",
        "Требуется реализовать одну из классических метрик для оценки качества кластеризации. Задача кластеризации $-$ это, грубо говоря, задача разбить набор данных на классы похожих. В данном случае объектами будут вектора из $\\mathbb{R}^d$, а мерой похожести евклидово расстояние.\n",
        "<img src=\"clustering_intro_clustersamplegraph.jpg\" width=\"500\"/>\n",
        "\n",
        "Требуется эффективно реализовать метрику силуэт для оценки качества кластеризации. Для этого необходимо реализовать функцию, которая принимает numpy.array размера $n \\times d$, а также список меток размера $n$, где $n$ $-$ число элементов, а $d$ $-$ размерность пространства. Функция должна возвращать одно число $-$ значение метрики.\n",
        "\n",
        "Суть метрики заключается в оценке двух параметров, характеризующих выделенные кластеры — компактность и отделимость.\n",
        "\n",
        "Положим, что $C_i$ — номер кластера для объекта $i$.\n",
        "\n",
        "$s_i$ — компактность кластеризации объекта $i$ определяется как среднее расстояние от него до всех объектов\n",
        "того же кластера:\n",
        "$$ s_i = \\dfrac{1}{|\\{j: C_j = C_i\\}| - 1} \\sum\\limits_{j: C_j=C_i} \\|x_i - x_j\\| $$\n",
        "\n",
        "$d_i$ — отделимость кластеризации объекта $i$ определяется как среднее расстояние от него до всех объектов\n",
        "второго по близости кластера:\n",
        "$$ \\min\\limits_{C:C\\neq C_i} \\dfrac{1}{|\\{ j: C_j = C \\}|} \\sum\\limits_{j: C_j=C} \\|x_i - x_j\\| $$\n",
        "\n",
        "Тогда силуэт объекта i:\n",
        "$$ \\text{sil}_i = \\dfrac{d_i - s_i}{\\max{\\{d_i, s_i\\}}} $$\n",
        "\n",
        "И, наконец, коэффициент силуэта для выборки определяется как среднее силуэтов объектов:\n",
        "$$ S = \\dfrac{1}{n} \\sum\\limits_{i} \\text{sil}_i $$\n",
        "\n",
        "На следующем тесте\n",
        "```\n",
        "data, labels = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [2.0, 2.0]]),\n",
        "               np.array([1, 0, 0, 1])\n",
        "```\n",
        "Результатом является `-0.15098532303997897`.\n",
        "\n",
        "На тесте\n",
        "```\n",
        "np.random.seed(1568)\n",
        "data = np.random.randn(5000, 1200)\n",
        "labels = np.random.randint(low=0, high=100, size=data.shape[0])\n",
        "```\n",
        "Результат работы равен `-0.006423534504746837`, а время работы составляет порядка 0.6с.\n",
        "\n",
        "Ваша реализация должна удовлетворять следующим требованиям:\n",
        "1. При вычислении не должно возникать warning, бесконечностей и nan-ов\n",
        "2. Используйте не более одного цикла\n",
        "3. Учтите, что метки кластеров могут идти не по порядку и принимать произвольные значения\n",
        "4. Если в данных присутствует один кластер, то считайте что силуэт равен 0\n",
        "5. Если $s_i = d_i = 0$, то $\\text{sil}_i = 0$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def find_si(elem, arr):\n",
        "    ans = 0\n",
        "    for el in arr:\n",
        "        #print(el, elem)\n",
        "        ans += LA.norm(el - elem, 2)\n",
        "    return ans\n",
        "\n",
        "\n",
        "def find_di(elem, label, dictionary):\n",
        "    min = -1\n",
        "    for key in dictionary:\n",
        "        if key != label:\n",
        "            tmp = find_si(elem, dictionary[key])/len(dictionary[key])\n",
        "            if min == -1 or tmp < min:\n",
        "                min = tmp\n",
        "    return min\n",
        "\n",
        "def metric(array, labels):\n",
        "    # разбиваем выборку на кластеры\n",
        "    labels_list = np.unique(labels)\n",
        "    clastering_groups = {}\n",
        "    for i in range(len(array)):\n",
        "        if labels[i] in clastering_groups:\n",
        "            clastering_groups[labels[i]] += [np.array(array[i])]\n",
        "        else:\n",
        "            clastering_groups[labels[i]] = [np.array(array[i])]\n",
        "\n",
        "    ans = 0\n",
        "    for key in tqdm(clastering_groups):\n",
        "        for i in range(len(clastering_groups[key])):\n",
        "            d_i = find_di(clastering_groups[key][i], key, clastering_groups)\n",
        "\n",
        "            mass = clastering_groups[key].copy()\n",
        "            mass.pop(i)\n",
        "\n",
        "            s_i = find_si(clastering_groups[key][i], mass)/(len(mass))\n",
        "            ans += (d_i - s_i) / max(d_i, s_i)\n",
        "    return ans / len(labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "DtOtxjLEdVfP"
      },
      "id": "DtOtxjLEdVfP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, labels = np.array([[0.0, 0.0, 0.99], [0.99, 0.0,  1.0], [1.0,0.99, 0.0], [2.0,0.99,  2.0]], dtype=object), np.array([1, 0, 0, 1])\n",
        "\n",
        "print(metric(data, labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioVAalrQMQfG",
        "outputId": "63f4fd65-6356-437d-a328-e2c0f090943b"
      },
      "id": "ioVAalrQMQfG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 1467.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d_i 1.3552868400042086\n",
            "d_i 1.984088259566684\n",
            "d_i 1.361079522697943\n",
            "d_i 1.9782955768729495\n",
            "-0.09520438962151723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, labels = np.array([[0.0, 0.0],[0.0, 0.4], [6.0, 0.0], [0.0, 8.0], [0.0,  1.0], [1.0, 0.0], [2.0, 2.0]], dtype=object), np.array([1, 0, 0, 1, 1, 1, 0])\n",
        "\n",
        "print(metric(data, labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2uwFRCQcR_A",
        "outputId": "6f1e9497-c25b-4b52-fd7e-e18b54a83e93"
      },
      "id": "b2uwFRCQcR_A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 1644.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d_i 3.076142374915397\n",
            "d_i 7.974851773445587\n",
            "d_i 2.9729435025993367\n",
            "d_i 2.771033646308897\n",
            "d_i 2.4192582403567253\n",
            "d_i 6.770690632574555\n",
            "d_i 3.4062796000206323\n",
            "-0.0773814977625548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1568)\n",
        "data = np.random.randn(2000, 1200)\n",
        "labels = np.random.randint(low=0, high=100, size=data.shape[0])\n",
        "print(metric(data, labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG7mCwA4dSpB",
        "outputId": "4f2675ab-9a1a-496e-90c6-cbf041f992d5"
      },
      "id": "eG7mCwA4dSpB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:29<00:00,  3.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.00977356384492866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1568)\n",
        "data = np.random.randn(2000, 1200)\n",
        "labels = np.random.randint(low=0, high=100, size=data.shape[0])\n",
        "print(metric(data, labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK84Wlj2MUdv",
        "outputId": "a34523f8-87cd-40fa-ee2f-4f0b3eac9339"
      },
      "id": "FK84Wlj2MUdv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Я убил на это задание 2 чистых дня. В итоге есть две версии\n",
        "# Если счиать матрицу попарных расстояний заранее, то она не влезает в озу\n",
        "# Если считать на ходу попарные расстояния от вектора до всех остальных, то это 2 минуты\n",
        "# если я пробую считать расстояние не от одного вектора, а от кластера на каждой\n",
        "# итеррации, то это тоже не пролезает в память. \n",
        "\n",
        "\n",
        "# вариант 1\n",
        "\n",
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "from tqdm import tqdm\n",
        "\n",
        "def metric(array, labels):\n",
        "    \n",
        "    size = len(array)\n",
        "    vector_size = array[0].size\n",
        "    \n",
        "    # привожу все к np.array\n",
        "    labels = np.array(labels, dtype=\"double\")\n",
        "    array = np.array(array, dtype=\"double\")\n",
        "\n",
        "    # разбиение на кластеры\n",
        "    a = np.column_stack([array, labels])\n",
        "    a = a[a[:, vector_size].argsort()]\n",
        "\n",
        "    # границы класторов в массиве\n",
        "    clasters_borders = np.unique(a[:, vector_size], return_index=True)[1][1:]\n",
        "\n",
        "    # массив из кластеров\n",
        "    clasters = np.array(np.split(a[:, :vector_size], clasters_borders), dtype=object)\n",
        "\n",
        "    claster_sizes = list(map(lambda x: x.shape[0], clasters))\n",
        "    a = a[:, :vector_size]\n",
        "\n",
        "    # добавлю граничные точки в массив границ кластеров\n",
        "    clasters_borders_1 = np.concatenate([np.array([0]), clasters_borders, np.array([size])])\n",
        "\n",
        "    dist_matrix = LA.norm(a[:, None] - a[None, :], 2, axis=2)\n",
        "    #print(dist_matrix)\n",
        "\n",
        "    ans = 0\n",
        "    ans_1 = 0\n",
        "    # иду по всем возможным кластерам\n",
        "    for claster_number, claster in tqdm(enumerate(clasters)):\n",
        "        # рассчет расстояния от каждого элемента кластера до всех остальных\n",
        "        dist = LA.norm(a[clasters_borders_1[claster_number]:clasters_borders_1[claster_number + 1]][:, None] - a[None, :], 2, axis=2)\n",
        "        element_matrix_line_1 = np.hsplit(dist, clasters_borders)\n",
        "        d = np.array(list(map(lambda x: np.sum(x, axis=1), element_matrix_line_1)))\n",
        "        s_i = d[claster_number]\n",
        "        tmp = np.array(np.delete(d, claster_number, axis=0))\n",
        "        claster_sizes_tmp = claster_sizes.copy()\n",
        "        claster_sizes_tmp.pop(claster_number)\n",
        "        tmp = tmp/np.array(np.array(claster_sizes_tmp)[:, None])\n",
        "        d_i = np.min(tmp, axis=0)\n",
        "        ans_1 += np.sum((d_i - s_i) / np.max(np.column_stack([s_i, d_i]), axis=1))\n",
        "\n",
        "\n",
        "    return ans_1/len(a)\n",
        "\n",
        "data, labels = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [2.0, 2.0]], dtype=object), np.array([1, 0, 0, 1])\n",
        "print(metric(data, labels))\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# вариант 2\n",
        "\n",
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "def metric(array, labels):\n",
        "    # список возможных меток\n",
        "\n",
        "    # привожу все к np.array\n",
        "    labels = np.array(labels, dtype=\"double\")\n",
        "    array = np.array(array, dtype=\"double\")\n",
        "\n",
        "    # разбиение на кластеры\n",
        "    a = np.column_stack([array, labels])\n",
        "    a = a[a[:, array[0].size].argsort()]\n",
        "    # границы класторов в массиве\n",
        "    clasters_borders = np.unique(a[:, array[0].size], return_index=True)[1][1:]\n",
        "\n",
        "    # массив из кластеров\n",
        "    clasters = np.array(np.split(a[:, :array[0].size], clasters_borders), dtype=object)\n",
        "\n",
        "    # массив из всех векторов, отсортированный, где я знаю все границы кластеров\n",
        "    a = np.array(list(map(lambda x: x[:array[0].size], a)))\n",
        "\n",
        "    # добавлю граничные точки в массив границ кластеров\n",
        "    clasters_borders_1 = np.concatenate([np.array([0]), clasters_borders], axis=0)\n",
        "    clasters_borders_1 = np.concatenate([clasters_borders_1, np.array([len(a)])], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "    ans = 0\n",
        "    # иду по всем возможным кластерам\n",
        "    print(len(clasters))\n",
        "    for claster_number, claster in tqdm(enumerate(clasters)):\n",
        "        # рассчет расстояния от каждого элемента кластера до всех остальных\n",
        "\n",
        "        dist = LA.norm(a[clasters_borders_1[claster_number]:clasters_borders_1[claster_number + 1]][:, None] - a[None, :], 2, axis=2)\n",
        "        for i in range(len(claster)):\n",
        "            # calaster_number - номер кластера\n",
        "            # i - номер элемента в кластере\n",
        "            element_matrix_line = np.array(np.split(dist[i], clasters_borders), dtype=object)\n",
        "            s_i = np.sum(element_matrix_line[claster_number]) / (len(claster) -1)\n",
        "            tmp = np.array(np.delete(element_matrix_line, claster_number, axis=0))\n",
        "            # размеры кластеров\n",
        "\n",
        "            lengths = list(map(lambda x: x.size, tmp))\n",
        "\n",
        "            d_i = np.min(np.array(list(map(np.sum, tmp))) / lengths)\n",
        "            ans += (d_i - s_i) / max(d_i, s_i)\n",
        "    return ans/len(a)\n",
        "\n",
        "data = np.array(np.random.randn(5000, 1200), dtype=object)\n",
        "labels = np.random.randint(low=0, high=100, size=data.shape[0])\n",
        "print(metric(data, labels))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RoL2TbxfGZZ",
        "outputId": "6606a9ed-d3e8-48d3-8323-dfc7b4c8e559"
      },
      "id": "9RoL2TbxfGZZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2it [00:00, 2614.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.15098532303997897\n",
            "100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [02:03,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.006436606676688048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2,3],[3,4,5],[7,7,7],[6,6,6]])\n",
        "np.split(a, [3], axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmCAW3ElvFpc",
        "outputId": "c8a07a8a-af75-4f30-ef80-f0fa0dd8943f"
      },
      "id": "RmCAW3ElvFpc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[1, 2, 3],\n",
              "        [3, 4, 5],\n",
              "        [7, 7, 7]]), array([[6, 6, 6]])]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc57eeae",
      "metadata": {
        "id": "cc57eeae"
      },
      "source": [
        "# 4. Монотонная нелинейная функция"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d854f2d",
      "metadata": {
        "id": "8d854f2d"
      },
      "source": [
        "Рассмотрим произвольную монотонную непрерывную на отрезке $[-T, T]$ функцию $f(x)$. Ее можно приблизить кусочно-линейной непрерывной функцией $g(x)$ следующим образом. Построим равномерную сетку\n",
        "$$ x_0=-T, x_1, x_2, \\dots, x_{K-2}, x_{K-1} = T $$\n",
        "на отрезке $[-T, T]$ с $K$ узлами. Пусть $g(-T) = b_0$ и $g(x)$ линейна на отрезках $[x_{i-1}, x_i]$. Поскольку $g(x)$ непрерывна, она однозначно задается значениями $b_0$ и коэффицентами наклона $\\alpha_i$. Действительно,\n",
        "$$ g(x_0) = b_0 $$\n",
        "$$ g(x_i) = g(x_{i-1}) + \\alpha_{i-1} (x_i - x_{i-1}), ~~ i=1,\\dots,K-1 $$\n",
        "\n",
        "При этом на практике неотрицательные углы наклона часто удобно параметризовать как\n",
        "$$ \\alpha_i = \\log(1 + e^{v_i}) $$\n",
        "\n",
        "Пусть задано значение $b_0$ и набор $v_i$, $i=0, 1, \\dots, K-2$. Пусть также задан тензор $X$ значений $x_j$ произвольного размера. Гарантируется, что $-T \\le x_j \\le T$. Необходимо реализовать функцию, которая бы поэлементно вычисляла значения $g(X)$ (как это делают универсальные функции в numpy). Реализация не должна использовать циклов и сторонних библиотек, в том числе numba, `@vectorize` и прочее.\n",
        "\n",
        "Для демонстрации правильности работы визуализируйте график функции с помощью matplotlib для нескольких разумных частных случаев.\n",
        "\n",
        "Ориентировочное время работы для тензора $500 \\times 500 \\times 500$ и $K=1000$ равно 4.5с на 1 ядре."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kMhvksNMBxgO"
      },
      "id": "kMhvksNMBxgO",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
